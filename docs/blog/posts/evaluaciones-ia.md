---
title: Evaluaciones en IA, Lo que todos dicen hacer y pocos hacen bien
date: 2025-01-09
---

# Evaluaciones en IA: Lo que todos dicen hacer y pocos hacen bien

**Marcelo Acosta Cavalero**  


---

Si preguntamos en LinkedIn o Twitter\* sobre evaluaciones (evals) en proyectos de IA, encontraremos cientos de posts hablando del tema. Todo el mundo parece ser experto en evals. Sin embargo, la realidad es bastante diferente: son pocas las empresas que realmente implementan evaluaciones sistemáticas en sus proyectos de IA, y menos aún las que lo hacen correctamente.

Pero antes de seguir, vamos a lo básico: ¿qué son realmente las evals?

Imaginen que tienen un empleado nuevo. No basta con contratarlo y asumir que todo va bien, necesitan evaluar su desempeño. Las evals son exactamente eso, pero para sistemas de IA. Son métodos sistemáticos para medir qué tan bien está funcionando tu modelo de IA en las tareas específicas para las que lo implementaste. Y no, no hablo de esa sensación de "funciona bien" que todos tenemos cuando probamos un chatbot un par de veces.

Cuando hablamos de implementar evals, estamos hablando de números concretos, no de sensaciones. Por ejemplo, si implementaste un sistema de IA para clasificar correos de soporte, no basta con que "parezca que funciona bien". Necesitas saber exactamente qué porcentaje de correos está clasificando correctamente, cuántos está enviando al departamento equivocado, y cuánto tiempo está tardando en tomar estas decisiones. Y aquí viene lo interesante: muchas empresas descubren que su IA, que parecía funcionar perfectamente en las demos, tiene un rendimiento muy diferente cuando se enfrenta a datos reales del día a día.

El problema es que implementar evals no es tan simple como aplicar un test de múltiple opción. Requiere definir métricas específicas para tu caso de uso, crear conjuntos de datos de prueba representativos
